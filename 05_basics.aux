\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Markowitz_1952}
\citation{Buckle_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theory}{11}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{sec:grundlagen}{{2}{11}{Theory}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Econometric Motivation}{11}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Portfolio Theory}{11}{subsection.2.1.1}\protected@file@percent }
\citation{Kuhn_Tucker_2014}
\newlabel{eq: Return simple definition}{{2.1}{12}{Portfolio Theory}{equation.2.1.1}{}}
\newlabel{eq:Return_Rate_Definition}{{2.2}{12}{Portfolio Theory}{equation.2.1.2}{}}
\newlabel{eq: Normalization of Sum of Investments}{{2.3}{12}{Portfolio Theory}{equation.2.1.3}{}}
\newlabel{eq: total rate of return}{{2.4}{12}{Portfolio Theory}{equation.2.1.4}{}}
\newlabel{eq:Markowitz Optimisation Problem}{{2.5}{12}{Portfolio Theory}{equation.2.1.5}{}}
\newlabel{eq:Optimisation}{{2.5a}{12}{Portfolio Theory}{equation.2.1.1}{}}
\newlabel{eq:Conditions}{{2.5b}{12}{Portfolio Theory}{equation.2.1.2}{}}
\newlabel{eq: mean return least-variance solution}{{2.6}{12}{Portfolio Theory}{equation.2.1.6}{}}
\citation{Ledoit_2004}
\newlabel{eq: optimal distribution of weights}{{2.7}{13}{Portfolio Theory}{equation.2.1.7}{}}
\newlabel{eq:Solution space curves}{{2.8}{13}{Portfolio Theory}{equation.2.1.8}{}}
\newlabel{eq:Solution space curve}{{2.8a}{13}{Portfolio Theory}{equation.2.1.1}{}}
\newlabel{eq:Solution space curve conditions}{{2.8b}{13}{Portfolio Theory}{equation.2.1.2}{}}
\newlabel{eq:sample_cov}{{2.9}{13}{Portfolio Theory}{equation.2.1.9}{}}
\newlabel{sec:portfolio}{{2.1.1}{13}{Portfolio Theory}{equation.2.1.9}{}}
\citation{Ross_2013}
\citation{Ross_n_Roll_1995}
\citation{Fama_1993}
\citation{Fama_1996}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Capital Asset Pricing Model}{14}{subsection.2.1.2}\protected@file@percent }
\newlabel{eq: market portfolio capm}{{2.10}{14}{Capital Asset Pricing Model}{equation.2.1.10}{}}
\newlabel{eq: expected return any asset capm}{{2.11}{14}{Capital Asset Pricing Model}{equation.2.1.11}{}}
\newlabel{eq: beta capm}{{2.12}{14}{Capital Asset Pricing Model}{equation.2.1.12}{}}
\newlabel{eq: expected return of portfolio capm}{{2.13}{14}{Capital Asset Pricing Model}{equation.2.1.13}{}}
\newlabel{eq:efficiency line capm}{{2.14}{14}{Capital Asset Pricing Model}{equation.2.1.14}{}}
\newlabel{eq:Expected value market}{{2.14a}{14}{Capital Asset Pricing Model}{equation.2.1.1}{}}
\newlabel{eq:variance market}{{2.14b}{14}{Capital Asset Pricing Model}{equation.2.1.2}{}}
\newlabel{eq: capm pricing formula}{{2.15}{14}{Capital Asset Pricing Model}{equation.2.1.15}{}}
\newlabel{eq:expected_return_with_risk_capm}{{2.16}{14}{Capital Asset Pricing Model}{equation.2.1.16}{}}
\newlabel{eq: excess return}{{2.17}{14}{Capital Asset Pricing Model}{equation.2.1.17}{}}
\citation{Fama_French_2004}
\citation{Everitt_1984}
\citation{Bishop_2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Arbitrage Pricing Theory}{15}{subsection.2.1.3}\protected@file@percent }
\newlabel{sec:apt}{{2.1.3}{15}{Arbitrage Pricing Theory}{subsection.2.1.3}{}}
\newlabel{eq: Three factor model}{{2.18}{15}{Arbitrage Pricing Theory}{equation.2.1.18}{}}
\newlabel{eq:Arbitrage Pricing Model}{{2.19}{15}{Arbitrage Pricing Theory}{equation.2.1.19}{}}
\newlabel{eq:asset return factor structure}{{2.19a}{15}{Arbitrage Pricing Theory}{equation.2.1.1}{}}
\newlabel{eq:expected excess returns}{{2.19b}{15}{Arbitrage Pricing Theory}{equation.2.1.2}{}}
\newlabel{eq: GPLVM form of Arbitrage Pricing Theory}{{2.20}{15}{Arbitrage Pricing Theory}{equation.2.1.20}{}}
\newlabel{sec:capm}{{2.1.3}{15}{Arbitrage Pricing Theory}{equation.2.1.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}ARCH and GARCH}{16}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline ARCH}{16}{section*.6}\protected@file@percent }
\newlabel{eq: ARCH process}{{2.21}{16}{ARCH}{equation.2.1.21}{}}
\newlabel{eq: ARCH sigma series}{{2.22}{16}{ARCH}{equation.2.1.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline GARCH}{16}{section*.7}\protected@file@percent }
\newlabel{eq:GARCH definition}{{2.23}{16}{GARCH}{equation.2.1.23}{}}
\newlabel{eq:GARCH main process}{{2.23a}{16}{GARCH}{equation.2.1.1}{}}
\newlabel{eq:GARCH noise}{{2.23b}{16}{GARCH}{equation.2.1.2}{}}
\newlabel{eq:GARCH variance}{{2.23c}{16}{GARCH}{equation.2.1.3}{}}
\newlabel{eq:GARCH lag length}{{2.24}{16}{GARCH}{equation.2.1.24}{}}
\newlabel{eq:GARCH lag ARCH}{{2.24a}{16}{GARCH}{equation.2.1.1}{}}
\newlabel{eq:GARCH estimate autocorrelations}{{2.24b}{16}{GARCH}{equation.2.1.2}{}}
\newlabel{sec:arch}{{2.1.4}{16}{GARCH}{equation.2.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Stochastic Process Models}{17}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Introduction}{17}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Fair Coinflip}}{17}{figure.caption.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Fair and unfair coinflip comparison}}{18}{figure.caption.9}\protected@file@percent }
\newlabel{sec:introduction}{{2.2.1}{18}{Introduction}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Bayesian Statistics}{19}{subsection.2.2.2}\protected@file@percent }
\newlabel{Bayes Rule for probabilities. }{{2.25}{19}{Bayesian Statistics}{equation.2.2.25}{}}
\newlabel{Bayes Rule for probability distributions. }{{2.26}{19}{Bayesian Statistics}{equation.2.2.26}{}}
\newlabel{Bayes Rule for Model Comparison}{{2.27}{19}{Bayesian Statistics}{equation.2.2.27}{}}
\newlabel{eq:Bayes_with_intractable_term}{{2.28}{20}{Bayesian Statistics}{equation.2.2.28}{}}
\newlabel{eq: Variational Distribution}{{2.29}{20}{Bayesian Statistics}{equation.2.2.29}{}}
\newlabel{eq: Expectation maximisation KL-Divergence}{{2.30}{20}{Bayesian Statistics}{equation.2.2.30}{}}
\newlabel{eq: ELBO Intro}{{2.31}{20}{Bayesian Statistics}{equation.2.2.31}{}}
\newlabel{eq:new_KL_ELBO}{{2.32}{20}{Bayesian Statistics}{equation.2.2.32}{}}
\newlabel{eq:evidence_log}{{2.33}{20}{Bayesian Statistics}{equation.2.2.33}{}}
\newlabel{eq: Variational Distribution Factorisation}{{2.34}{21}{Bayesian Statistics}{equation.2.2.34}{}}
\newlabel{eq: VB best Distribution}{{2.35}{21}{Bayesian Statistics}{equation.2.2.35}{}}
\newlabel{sec:bayes}{{2.2.2}{21}{Bayesian Statistics}{equation.2.2.35}{}}
\citation{Rasmussen_06}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Gaussian Processes}{22}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Weight Space View}{22}{section*.10}\protected@file@percent }
\newlabel{eq:Linear Regression Model}{{2.36}{22}{Weight Space View}{equation.2.2.36}{}}
\newlabel{eq: linear regression function}{{2.36a}{22}{Weight Space View}{equation.2.2.1}{}}
\newlabel{eq: observed target value}{{2.36b}{22}{Weight Space View}{equation.2.2.2}{}}
\newlabel{eq:Likelihood Weight Space View}{{2.37}{22}{Weight Space View}{equation.2.2.37}{}}
\newlabel{eq:likelihood wieght space 1}{{2.37a}{22}{Weight Space View}{equation.2.2.1}{}}
\newlabel{eq:likelihood weight space 2}{{2.37b}{22}{Weight Space View}{equation.2.2.2}{}}
\newlabel{Distribution of weights using a zero mean Gaussian with covariance matrix.}{{2.38}{22}{Weight Space View}{equation.2.2.38}{}}
\newlabel{eq: Marginal likelihood as normalizing constant}{{2.39}{22}{Weight Space View}{equation.2.2.39}{}}
\citation{Rasmussen_06}
\newlabel{Bayes Rule for linear Regression}{{2.40}{23}{Weight Space View}{equation.2.2.40}{}}
\newlabel{Unnormalized posterior}{{2.41}{23}{Weight Space View}{equation.2.2.41}{}}
\newlabel{eq:Gaussian posterior predictive distribution}{{2.42}{23}{Weight Space View}{equation.2.2.42}{}}
\newlabel{eq:predictive distribution 1}{{2.42a}{23}{Weight Space View}{equation.2.2.1}{}}
\newlabel{eq: predicitve distribution 2}{{2.42b}{23}{Weight Space View}{equation.2.2.2}{}}
\newlabel{eq:Feature Space Gaussian process}{{2.43}{23}{Weight Space View}{equation.2.2.43}{}}
\newlabel{eq: feature space model}{{2.43a}{23}{Weight Space View}{equation.2.2.1}{}}
\newlabel{eq: predictive distribution mean}{{2.43b}{23}{Weight Space View}{equation.2.2.2}{}}
\newlabel{eq: predictive distribution covariance}{{2.43c}{23}{Weight Space View}{equation.2.2.3}{}}
\newlabel{Rewritten Feature Space Gaussian Process evaluated in data space.}{{2.44}{23}{Weight Space View}{equation.2.2.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Function Space View}{23}{section*.11}\protected@file@percent }
\newlabel{eq:Gaussian_process_function_space_view}{{2.45}{24}{Function Space View}{equation.2.2.45}{}}
\newlabel{eq:function space view mean}{{2.45a}{24}{Function Space View}{equation.2.2.1}{}}
\newlabel{eq:function space view covariance function}{{2.45b}{24}{Function Space View}{equation.2.2.2}{}}
\newlabel{fuinction space view gaussian process}{{2.45c}{24}{Function Space View}{equation.2.2.3}{}}
\newlabel{eq:Function space view linear regression mean and covariance}{{2.46}{24}{Function Space View}{equation.2.2.46}{}}
\newlabel{eq:function space linear mean}{{2.46a}{24}{Function Space View}{equation.2.2.1}{}}
\newlabel{eq:function space linear covariance}{{2.46b}{24}{Function Space View}{equation.2.2.2}{}}
\newlabel{Random Gaussian vector}{{2.47}{24}{Function Space View}{equation.2.2.47}{}}
\newlabel{eq:squared-exponential}{{2.48}{24}{Function Space View}{equation.2.2.48}{}}
\newlabel{eq:joint_distribution_according_to_prior}{{2.49}{24}{Function Space View}{equation.2.2.49}{}}
\newlabel{conditioned/joint Gaussian prior}{{2.50}{24}{Function Space View}{equation.2.2.50}{}}
\newlabel{eq:joint_gaussian_distribution_according_to_prior_with_noise}{{2.51}{24}{Function Space View}{equation.2.2.51}{}}
\newlabel{eq: Key predictive equations for Gaussian process regression}{{2.52}{25}{Function Space View}{equation.2.2.52}{}}
\newlabel{eq:Key_predictive_equations_for_GP_reg}{{2.52}{25}{Function Space View}{equation.2.2.1}{}}
\newlabel{eq:marginal_likelihood_function_space_view}{{2.53}{25}{Function Space View}{equation.2.2.53}{}}
\newlabel{eq:Log_marginal_likelihood}{{2.54}{25}{Function Space View}{equation.2.2.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces GP prior samples}}{25}{figure.caption.12}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:prior_squ_exp}{{2.3}{25}{GP prior samples}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Random data from sine function with Gaussian noise}}{26}{figure.caption.13}\protected@file@percent }
\newlabel{fig:generated_data}{{2.4}{26}{Random data from sine function with Gaussian noise}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Trained GP samples with covariance interval}}{26}{figure.caption.14}\protected@file@percent }
\newlabel{fig:GP_sqexp_samples}{{2.5}{26}{Trained GP samples with covariance interval}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Trained GP with covariance intervals}}{26}{figure.caption.14}\protected@file@percent }
\newlabel{fig:GP_confidence_intervals}{{2.6}{26}{Trained GP with covariance intervals}{figure.caption.14}{}}
\newlabel{sec:gp}{{2.2.3}{27}{Function Space View}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Gaussian Kernel Functions}{27}{subsection.2.2.4}\protected@file@percent }
\newlabel{eq:positive_semidefiniteness_of_kernel_functions}{{2.55}{27}{Gaussian Kernel Functions}{equation.2.2.55}{}}
\newlabel{eq:mean_square_derivative_of_i-th_direction}{{2.56}{27}{Gaussian Kernel Functions}{equation.2.2.56}{}}
\newlabel{eq:linear_kernel_function}{{2.57}{27}{Gaussian Kernel Functions}{equation.2.2.57}{}}
\newlabel{eq:exponential_kernel_function}{{2.58}{27}{Gaussian Kernel Functions}{equation.2.2.58}{}}
\citation{Rasmussen_06}
\citation{Rasmussen_06}
\newlabel{eq:squared_exponential_kernel}{{2.59}{28}{Gaussian Kernel Functions}{equation.2.2.59}{}}
\newlabel{eq:matern_32_kernel}{{2.60}{28}{Gaussian Kernel Functions}{equation.2.2.60}{}}
\newlabel{eq:matern_52_kernel}{{2.61}{28}{Gaussian Kernel Functions}{equation.2.2.61}{}}
\newlabel{eq:matern_kernel_class}{{2.62}{28}{Gaussian Kernel Functions}{equation.2.2.62}{}}
\newlabel{sec:kernels}{{2.2.4}{28}{Gaussian Kernel Functions}{figure.caption.15}{}}
\newlabel{fig:lengthscale}{{\caption@xref {fig:lengthscale}{ on input line 49}}{29}{Gaussian Kernel Functions}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Lengthscale influence on samples}}{29}{figure.caption.15}\protected@file@percent }
\citation{Tipping_Bishop_1999_1}
\citation{Tipping_Bishop_1999_2}
\citation{Lawrence_2005}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Gaussian Process Latent Variable Models}{30}{section.2.3}\protected@file@percent }
\newlabel{eq:Factor_Analysis}{{2.63}{30}{Gaussian Process Latent Variable Models}{equation.2.3.63}{}}
\newlabel{eq: Factor analysis results}{{2.64}{31}{Gaussian Process Latent Variable Models}{equation.2.3.64}{}}
\newlabel{eq: x-conditional probability dist over t-space}{{2.65}{31}{Gaussian Process Latent Variable Models}{equation.2.3.65}{}}
\newlabel{eq: marginal distribution t}{{2.66}{31}{Gaussian Process Latent Variable Models}{equation.2.3.66}{}}
\newlabel{eq: log likelihood p-pca}{{2.67}{31}{Gaussian Process Latent Variable Models}{equation.2.3.67}{}}
\newlabel{eq: generating procedure GPLVM}{{2.68}{31}{Gaussian Process Latent Variable Models}{equation.2.3.68}{}}
\newlabel{eq: marginal likelihood of data gplvm}{{2.69}{31}{Gaussian Process Latent Variable Models}{equation.2.3.69}{}}
\newlabel{sec:GPLVM}{{2.3}{31}{Gaussian Process Latent Variable Models}{equation.2.3.69}{}}
\citation{Shah_14}
\citation{Shah_14}
\citation{Dawid_1981}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Student-t-Process}{32}{subsection.2.3.1}\protected@file@percent }
\newlabel{eq:}{{2.70}{32}{Student-t-Process}{equation.2.3.70}{}}
\newlabel{eq:Wishart Distribution}{{2.70a}{32}{Student-t-Process}{equation.2.3.1}{}}
\newlabel{eq:Wishart distribution definition}{{2.70b}{32}{Student-t-Process}{equation.2.3.2}{}}
\newlabel{eq:}{{2.71}{32}{Student-t-Process}{equation.2.3.71}{}}
\newlabel{eq:Inverse Wishart distribution}{{2.71a}{32}{Student-t-Process}{equation.2.3.1}{}}
\newlabel{eq:Inverse Wishart distribution definition}{{2.71b}{32}{Student-t-Process}{equation.2.3.2}{}}
\newlabel{eq: Inverse Wishart Process}{{2.72}{32}{Student-t-Process}{equation.2.3.72}{}}
\newlabel{eq:Student-t process}{{2.73}{32}{Student-t-Process}{equation.2.3.73}{}}
\newlabel{eq:inverse wishart covariance kernel}{{2.73a}{32}{Student-t-Process}{equation.2.3.1}{}}
\newlabel{eq:hierarchical gaussian process with iwp kernel}{{2.73b}{32}{Student-t-Process}{equation.2.3.2}{}}
\newlabel{eq:multivariate Student-t distributed data}{{2.74}{32}{Student-t-Process}{equation.2.3.74}{}}
\newlabel{eq:multivariate Student-t shorthand}{{2.74a}{32}{Student-t-Process}{equation.2.3.1}{}}
\newlabel{eq:multivariate Student-t distributed data def}{{2.74b}{32}{Student-t-Process}{equation.2.3.2}{}}
\citation{Shah_14}
\newlabel{eq:mean and cov studt}{{2.75}{33}{Student-t-Process}{equation.2.3.75}{}}
\newlabel{eq:mean studt}{{2.75a}{33}{Student-t-Process}{equation.2.3.1}{}}
\newlabel{eq:cov studt}{{2.75b}{33}{Student-t-Process}{equation.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces GP samples example}}{33}{figure.caption.16}\protected@file@percent }
\newlabel{fig:GP_samples}{{2.8}{33}{GP samples example}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces TP samples example}}{33}{figure.caption.16}\protected@file@percent }
\newlabel{fig:TP_samples}{{2.9}{33}{TP samples example}{figure.caption.16}{}}
\newlabel{eq:multivariate student t conditional distribution}{{2.76}{34}{Student-t-Process}{equation.2.3.76}{}}
\newlabel{sec:student-t}{{2.3.1}{34}{Student-t-Process}{equation.2.3.1}{}}
\citation{Geyer_2011}
\citation{Andrieu_2003}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Algorithms for stochastic problem computation}{35}{section.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Metropolis Hastings Convergence Example}}{35}{figure.caption.17}\protected@file@percent }
\citation{Duane_1987}
\newlabel{eq:markov chain central limit theorem prerequisites}{{2.77}{36}{Algorithms for stochastic problem computation}{equation.2.4.77}{}}
\newlabel{eq:mean of initial markov chain step}{{2.77a}{36}{Algorithms for stochastic problem computation}{equation.2.4.1}{}}
\newlabel{eq:variance markov steps}{{2.77b}{36}{Algorithms for stochastic problem computation}{equation.2.4.2}{}}
\newlabel{eq:expected mean markov process}{{2.77c}{36}{Algorithms for stochastic problem computation}{equation.2.4.3}{}}
\newlabel{eq:markov chain convergence}{{2.78}{36}{Algorithms for stochastic problem computation}{equation.2.4.78}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Hamiltonian Monte Carlo}{36}{section*.18}\protected@file@percent }
\newlabel{eq: HMC joint density for regular and auxiliar variables}{{2.79}{36}{Hamiltonian Monte Carlo}{equation.2.4.79}{}}
\citation{Kucukelbir_2015}
\citation{stan_manual}
\citation{stan_manual}
\citation{Duchi_2011}
\newlabel{eq:HMC_independent_auxiliary_variables}{{2.80}{37}{Hamiltonian Monte Carlo}{equation.2.4.80}{}}
\newlabel{eq: HMC Hamiltonian}{{2.81}{37}{Hamiltonian Monte Carlo}{equation.2.4.81}{}}
\newlabel{eq:HMC Hamiltonian equations}{{2.82}{37}{Hamiltonian Monte Carlo}{equation.2.4.82}{}}
\newlabel{eq:HMC parameter Hamilton equation}{{2.82a}{37}{Hamiltonian Monte Carlo}{equation.2.4.1}{}}
\newlabel{eq:HMC auxiliary Hamiltonian equation}{{2.82b}{37}{Hamiltonian Monte Carlo}{equation.2.4.2}{}}
\newlabel{eq:HMC Leapfrog update equations}{{2.83}{37}{Hamiltonian Monte Carlo}{equation.2.4.83}{}}
\newlabel{eq:LF update rule momentum}{{2.83a}{37}{Hamiltonian Monte Carlo}{equation.2.4.1}{}}
\newlabel{eq:LF update rule pamaeters}{{2.83b}{37}{Hamiltonian Monte Carlo}{equation.2.4.2}{}}
\newlabel{eq: Metropolis Acceptance probability of a HMC step.}{{2.84}{37}{Hamiltonian Monte Carlo}{equation.2.4.84}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Stochastic Gradient Ascent}{38}{section*.19}\protected@file@percent }
\newlabel{sec:stochastic_gradient_ascent}{{2.4}{38}{Stochastic Gradient Ascent}{section*.19}{}}
\newlabel{sec:mcmc}{{2.4}{38}{Stochastic Gradient Ascent}{section*.19}{}}
\@setckpt{05_basics}{
\setcounter{page}{39}
\setcounter{equation}{84}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{Item}{5}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{lstnumber}{1}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{83}
\setcounter{section@level}{3}
\setcounter{lstlisting}{0}
}
